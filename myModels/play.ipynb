{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GNNAgg as agg\n",
    "# import GNNArch as arc\n",
    "# import GNNLayers as layers\n",
    "# import GNNModel as models\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import sys\n",
    "BASE_PATH = globals()['_dh'][0].parent.absolute()\n",
    "sys.path.insert(1, str(BASE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\"../models/data/\", name=\"Cora\", transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.GraphGNNModels(\n",
    "    in_channel=dataset.num_features,\n",
    "    edge_channel=dataset.num_edge_features,\n",
    "    out_channel=dataset.num_classes,\n",
    "    embedding_layer_num=3,\n",
    "    architecture_name='IterGNN',\n",
    "    layer_num=10,\n",
    "    layer_name='GCNConv',\n",
    "    hidden_size=64,\n",
    "    confidence_layer_num=3\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def running_test(net, test_data_loader, device,\n",
    "                 running_metric_name_list, test_loss_hist,\n",
    "                 epoch, step, global_step):\n",
    "    test_metric_list, _ = evaluate(net, test_data_loader, device,\n",
    "                                parallel_flag=False,\n",
    "                                metric_name_list=running_metric_name_list)\n",
    "    for mn in running_metric_name_list:\n",
    "        test_loss_hist[mn].append(np.mean(test_metric_list[mn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "global_step = 0\n",
    "layer_num_hist, loss_hist = [], []\n",
    "running_metric_name_list = [\"relative loss\", \"mse loss\"]\n",
    "test_loss_hist, test_gen_loss_hist = [{mn:[] for mn in running_metric_name_list} for _ in range(2)]\n",
    "epoch_num=10\n",
    "data_loader = DataLoader(dataset)\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "optimizer = Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epoch_num+1):\n",
    "        print(\"111\")\n",
    "        net.train()\n",
    "        print(data_loader)\n",
    "        \n",
    "        for step,data in enumerate(data_loader):\n",
    "            data = data.to(\"cpu\")\n",
    "            global_step += 1\n",
    "            pred = net(data)\n",
    "            y = data.y\n",
    "            print(y.size())\n",
    "            loss = F.mse_loss(pred.reshape(y.size()), y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_hist.append(loss.item())\n",
    "            layer_num_hist.append(layer_num)\n",
    "        running_test(net, data_loader, \"cpu\",\n",
    "                     running_metric_name_list, test_loss_hist,\n",
    "                     epoch, step, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7828],\n",
      "        [0.5856],\n",
      "        [0.1311],\n",
      "        [0.2514],\n",
      "        [0.3540]])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4])\n",
      "tensor([[0.7828],\n",
      "        [0.7828],\n",
      "        [0.7828],\n",
      "        [0.7828],\n",
      "        [0.5856],\n",
      "        [0.5856],\n",
      "        [0.5856],\n",
      "        [0.5856],\n",
      "        [0.1311],\n",
      "        [0.1311],\n",
      "        [0.1311],\n",
      "        [0.2514],\n",
      "        [0.2514],\n",
      "        [0.2514],\n",
      "        [0.2514],\n",
      "        [0.3540],\n",
      "        [0.3540],\n",
      "        [0.3540]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "aa = torch.rand(5,1)\n",
    "batch = torch.tensor([0,0,0,0,1,1,1,1,2,2,2,3,3,3,3,4,4,4])\n",
    "print(aa)\n",
    "print(batch)\n",
    "print(aa[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3160],\n",
       "        [-0.0029],\n",
       "        [-0.0029],\n",
       "        [ 0.1488],\n",
       "        [-0.0008]], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from OtherLayers import MLP\n",
    "mlp = MLP(size_list=[7,1])\n",
    "aa = torch.rand(5,7)\n",
    "batch = torch.tensor([0,0,0,3,4])\n",
    "bbb = global_max_pool(aa, batch)\n",
    "mlp(bbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNAgg import ReadoutLayers\n",
    "from torch_geometric.data import Data\n",
    "rr = ReadoutLayers('Max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "data1 = Data(x=aa, num_graphs=1)\n",
    "print(data1.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=aa, batch=batch, num_graphs=1)\n",
    "ppp = rr(data)\n",
    "qqq = mlp(ppp)\n",
    "qqq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.batch is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LobsterEncoder(\n",
       "  (module): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=3, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=2, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from OtherLayers import LobsterEncoder\n",
    "import torch.nn as nn\n",
    "aa = LobsterEncoder(in_channel=5, out_channel=1, layer_num=3, last_activation=nn.Identity)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import OneHotDegree\n",
    "from torch_geometric.utils import degree\n",
    "import torch\n",
    "from main.Planetoid_utils import add_noise\n",
    "dataset = TUDataset(root='data/', name=\"MUTAG\")\n",
    "# running_max = 0\n",
    "# for data in dataset:\n",
    "#     deg = max(degree(data.edge_index[0])).item()\n",
    "#     if deg > running_max:\n",
    "#         running_max = deg\n",
    "# print(running_max)\n",
    "dataset[0].x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4989,  0.8419,  1.7994, -1.4881, -0.2392, -0.9777,  0.6797],\n",
       "        [ 0.4956, -0.0920,  0.2642,  0.3930,  0.9706,  1.4442, -0.1691],\n",
       "        [ 1.4467,  0.5989, -0.6451, -0.2349,  0.6676, -2.0253,  0.1696],\n",
       "        [ 2.5653, -0.6892, -0.9036,  1.6700, -0.8507, -0.3002,  0.5359],\n",
       "        [-1.6184, -1.9339, -0.6903,  0.5359,  0.2972, -0.4479,  3.0432],\n",
       "        [ 1.5381, -0.0292,  1.4400,  0.6650,  1.8275,  0.2086, -1.1616],\n",
       "        [-1.4297,  0.2855, -0.0602,  0.3554,  0.1014, -0.7319, -2.1213],\n",
       "        [ 0.7748,  0.8108,  0.7299,  1.0317,  0.8967, -0.6605, -0.2472],\n",
       "        [ 0.1302, -2.6237,  0.2541,  0.3003,  0.0243, -0.0567, -1.4989],\n",
       "        [ 1.2966,  0.9576, -0.8157,  1.6909, -0.1964,  1.0285,  0.5211],\n",
       "        [-0.7091, -0.1175, -0.7209,  0.6056, -0.6699,  0.6292,  0.3205],\n",
       "        [ 1.8076, -0.4284,  0.2154,  0.9747,  0.2471,  0.0193,  1.0326],\n",
       "        [ 0.4988,  0.3517, -0.6324,  0.1111,  0.5408,  0.7150,  0.1840],\n",
       "        [ 2.4299,  1.3979, -0.0658, -0.8267, -0.6815,  0.8840,  0.7118],\n",
       "        [ 0.0200,  2.0374,  0.0040,  0.5008, -1.6285,  2.0523,  0.1010],\n",
       "        [-0.1800,  1.1413, -1.4710, -1.2757,  0.0808,  0.7139,  1.6034],\n",
       "        [-0.2429,  0.5512,  0.8038,  1.1142,  0.3953,  0.1175,  0.5055]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.tensor(np.random.normal(0, 1, dataset[0].x.size())) + dataset[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  6.,  8., 10.,  8.,  8.,  4.],\n",
       "        [ 9.,  9.,  9.,  7.,  7.,  6.,  7.],\n",
       "        [ 5.,  8.,  6., 10.,  8.,  7.,  6.],\n",
       "        [ 8.,  7., 10., 10.,  8.,  8.,  9.],\n",
       "        [ 6.,  6.,  5., 12., 11.,  7.,  5.],\n",
       "        [ 9.,  7.,  4.,  7.,  4., 10.,  9.],\n",
       "        [10.,  9.,  2.,  6.,  7.,  5.,  9.],\n",
       "        [ 6.,  7.,  9.,  9.,  8.,  6.,  5.],\n",
       "        [ 7.,  8.,  6.,  8.,  5.,  6.,  9.],\n",
       "        [ 6.,  8.,  6.,  6.,  8., 10.,  7.],\n",
       "        [ 6.,  8.,  7.,  9.,  6.,  6.,  7.],\n",
       "        [11., 12.,  8.,  9., 11.,  9.,  8.],\n",
       "        [ 6., 12.,  8., 12.,  6.,  8.,  8.],\n",
       "        [ 7.,  9., 10.,  8.,  7.,  5.,  7.],\n",
       "        [ 4.,  5.,  7.,  8.,  7.,  9.,  7.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for graph in dataset:\n",
    "    graph = add_noise(graph, 0.5)\n",
    "dataset[111].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0,  ..., 421, 421, 421],\n",
      "        [  1,   2,   3,  ..., 418, 419, 420]])\n",
      "tensor([[  0,   0,   0,  ..., 484, 484, 484],\n",
      "        [  3,   5,   6,  ..., 481, 482, 483]])\n",
      "tensor([[  0,   0,   0,  ..., 494, 494, 494],\n",
      "        [  1,   3,   6,  ..., 491, 492, 493]])\n",
      "tensor([[  0,   0,   0,  ..., 408, 408, 408],\n",
      "        [  1,   2,   3,  ..., 404, 405, 407]])\n",
      "tensor([[  0,   0,   0,  ..., 404, 404, 404],\n",
      "        [  1,  12,  14,  ..., 401, 402, 403]])\n",
      "tensor([[  0,   0,   0,  ..., 468, 468, 468],\n",
      "        [  1,   2,   3,  ..., 462, 464, 467]])\n",
      "tensor([[  0,   0,   0,  ..., 420, 420, 420],\n",
      "        [  5,   7,  10,  ..., 410, 412, 413]])\n",
      "tensor([[  0,   0,   0,  ..., 455, 455, 455],\n",
      "        [  1,   2,   3,  ..., 452, 453, 454]])\n",
      "tensor([[  0,   0,   0,  ..., 545, 545, 545],\n",
      "        [  1,   2,   4,  ..., 539, 540, 543]])\n",
      "tensor([[  0,   0,   0,  ..., 379, 379, 379],\n",
      "        [  1,   5,   7,  ..., 373, 374, 375]])\n",
      "tensor([[  0,   0,   0,  ..., 494, 494, 494],\n",
      "        [  3,   6,   8,  ..., 489, 491, 492]])\n",
      "tensor([[  0,   0,   0,  ..., 433, 433, 433],\n",
      "        [  1,   2,   3,  ..., 430, 431, 432]])\n",
      "tensor([[  0,   0,   0,  ..., 399, 399, 399],\n",
      "        [  2,   6,   8,  ..., 377, 391, 394]])\n",
      "tensor([[  0,   0,   0,  ..., 400, 400, 400],\n",
      "        [  5,   9,  11,  ..., 397, 398, 399]])\n",
      "tensor([[  0,   0,   0,  ..., 398, 399, 399],\n",
      "        [  1,   3,   4,  ..., 397, 395, 396]])\n",
      "tensor([[  0,   0,   0,  ..., 390, 390, 390],\n",
      "        [  1,   2,   3,  ..., 387, 388, 389]])\n",
      "tensor([[  0,   0,   0,  ..., 345, 345, 345],\n",
      "        [  1,   4,   6,  ..., 342, 343, 344]])\n",
      "tensor([[  0,   0,   0,  ..., 331, 331, 331],\n",
      "        [  1,   2,   6,  ..., 328, 329, 330]])\n",
      "tensor([[  0,   0,   0,  ..., 426, 426, 426],\n",
      "        [  1,   2,   3,  ..., 420, 424, 425]])\n",
      "tensor([[  0,   0,   0,  ..., 406, 406, 406],\n",
      "        [  1,   2,   3,  ..., 401, 402, 403]])\n",
      "tensor([[  0,   0,   0,  ..., 485, 485, 485],\n",
      "        [  1,   2,   3,  ..., 469, 479, 482]])\n",
      "tensor([[  0,   0,   0,  ..., 422, 422, 422],\n",
      "        [  1,   2,   3,  ..., 417, 418, 419]])\n",
      "tensor([[  0,   0,   0,  ..., 479, 479, 479],\n",
      "        [  2,   6,  10,  ..., 475, 476, 478]])\n",
      "tensor([[  0,   0,   0,  ..., 407, 407, 407],\n",
      "        [  1,   2,   3,  ..., 400, 401, 405]])\n",
      "tensor([[  0,   0,   0,  ..., 328, 328, 328],\n",
      "        [  1,   2,   3,  ..., 321, 324, 326]])\n",
      "tensor([[  0,   0,   0,  ..., 368, 368, 368],\n",
      "        [  1,   5,   6,  ..., 365, 366, 367]])\n",
      "tensor([[  0,   0,   0,  ..., 354, 354, 354],\n",
      "        [  1,   2,   3,  ..., 347, 350, 352]])\n",
      "tensor([[  0,   0,   0,  ..., 413, 413, 413],\n",
      "        [  1,   2,   3,  ..., 410, 411, 412]])\n",
      "tensor([[  0,   0,   0,  ..., 450, 450, 450],\n",
      "        [  1,   2,   3,  ..., 447, 448, 449]])\n",
      "tensor([[  0,   0,   0,  ..., 466, 466, 466],\n",
      "        [  1,   2,   3,  ..., 463, 464, 465]])\n",
      "tensor([[  0,   0,   0,  ..., 436, 436, 436],\n",
      "        [  1,   2,   3,  ..., 432, 433, 434]])\n",
      "tensor([[  0,   0,   0,  ..., 407, 407, 407],\n",
      "        [  1,   3,   7,  ..., 404, 405, 406]])\n",
      "tensor([[  0,   0,   0,  ..., 403, 403, 403],\n",
      "        [  1,   2,   3,  ..., 400, 401, 402]])\n",
      "tensor([[  0,   0,   0,  ..., 416, 416, 416],\n",
      "        [  4,   5,   7,  ..., 413, 414, 415]])\n",
      "tensor([[  0,   0,   0,  ..., 358, 358, 358],\n",
      "        [  1,   2,   3,  ..., 355, 356, 357]])\n",
      "tensor([[  0,   0,   0,  ..., 403, 403, 403],\n",
      "        [  1,   2,   3,  ..., 400, 401, 402]])\n",
      "tensor([[  0,   0,   0,  ..., 402, 402, 402],\n",
      "        [  4,   5,   6,  ..., 395, 398, 400]])\n",
      "tensor([[  0,   0,   0,  ..., 369, 369, 369],\n",
      "        [  1,   2,   3,  ..., 366, 367, 368]])\n",
      "tensor([[  0,   0,   0,  ..., 467, 467, 467],\n",
      "        [  1,   2,   3,  ..., 464, 465, 466]])\n",
      "tensor([[  0,   0,   0,  ..., 438, 438, 438],\n",
      "        [  1,   2,   3,  ..., 435, 436, 437]])\n",
      "tensor([[  0,   0,   0,  ..., 380, 380, 380],\n",
      "        [  1,   2,   3,  ..., 375, 376, 378]])\n",
      "tensor([[  0,   0,   0,  ..., 408, 408, 408],\n",
      "        [  1,   2,   3,  ..., 405, 406, 407]])\n",
      "tensor([[  0,   0,   0,  ..., 456, 456, 456],\n",
      "        [  2,   5,   6,  ..., 450, 451, 454]])\n",
      "tensor([[  0,   0,   0,  ..., 346, 346, 346],\n",
      "        [  2,   4,   5,  ..., 343, 344, 345]])\n",
      "tensor([[  0,   0,   0,  ..., 389, 389, 389],\n",
      "        [  1,   2,   3,  ..., 372, 378, 387]])\n",
      "tensor([[  0,   0,   0,  ..., 351, 351, 351],\n",
      "        [  2,   4,   5,  ..., 344, 346, 348]])\n",
      "tensor([[  0,   0,   0,  ..., 353, 353, 353],\n",
      "        [  6,  10,  22,  ..., 350, 351, 352]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "dataset = TUDataset(root='data/', name=\"IMDB-MULTI\", transform=OneHotDegree(88))\n",
    "train_loader = DataLoader(dataset, batch_size=32)\n",
    "for data in train_loader:\n",
    "    print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "a = nn.Sequential(\n",
    "    nn.Linear(10,12),\n",
    "    nn.ReLU()\n",
    ")\n",
    "for layer in a:\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m JumpingKnowledge\n\u001b[0;32m----> 2\u001b[0m JumpingKnowledge(\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/GitHubRepos/IterGNN/iterGNN/lib/python3.8/site-packages/torch_geometric/nn/models/jumping_knowledge.py:45\u001b[0m, in \u001b[0;36mJumpingKnowledge.__init__\u001b[0;34m(self, mode, channels, num_layers)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, mode: \u001b[39mstr\u001b[39m, channels: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m              num_layers: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m     46\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import JumpingKnowledge\n",
    "JumpingKnowledge(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = []\n",
    "\n",
    "a = np.concatenate((a, [1,2]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [False, True, True]\n",
    "sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = {\n",
    "    'bb': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bb': 10}\n"
     ]
    }
   ],
   "source": [
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = {\n",
    "    \"cc\": 12\n",
    "}\n",
    "aa.update(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bb': 10, 'cc': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=    0.1000\n"
     ]
    }
   ],
   "source": [
    "print(\"a={:.4f}\".format(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[0,1], [1,2]])\n",
    "a[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
